# =================================================================================
# PENTHENA AI Agent - v19.3 (ì´ˆê¸° í™”ë©´ UI ë‹¨ìˆœí™”)
# =================================================================================
# ì‘ì„±ì: Google Gemini/GPT along with Dave Han
# ì—…ë°ì´íŠ¸ ë‚ ì§œ: 2025-06-15
#
# ì£¼ìš” ë³€ê²½ ì‚¬í•­:
# 1. [UI/UX] ë©”ì¸ í™”ë©´ì˜ ì˜ˆì‹œ í”„ë¡¬í”„íŠ¸ ë²„íŠ¼ ë° ê´€ë ¨ ì»¨í…Œì´ë„ˆ ì™„ì „ ì œê±°
# 2. ì´ì „ ë²„ì „ì˜ ëª¨ë“  UI/UX ê°œì„  ë° ë²„ê·¸ ìˆ˜ì • ì‚¬í•­ í¬í•¨
# =================================================================================

import streamlit as st
if "cot_log" not in st.session_state:
    st.session_state["cot_log"] = []      # CoT ë¡œê·¸ ì €ì¥ìš©
if "long_term" not in st.session_state:
    st.session_state["long_term"] = {}    # ì¥ê¸° ë©”ëª¨ë¦¬ ì €ì¥ìš©
import openai, os, json, time, re
from dotenv import load_dotenv
from datetime import datetime, timedelta
import pytz, requests
import xml.etree.ElementTree as ET
import pandas as pd
import plotly.graph_objects as go
import plotly.express as px
from tavily import TavilyClient
from concurrent.futures import ThreadPoolExecutor

# --- 1. ê¸°ë³¸ ì„¤ì • ë° í™˜ê²½ë³€ìˆ˜ ë¡œë“œ ---
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")
tavily_api_key = os.getenv("TAVILY_API_KEY")
tavily = TavilyClient(api_key=tavily_api_key)

# === 1-A. Planner: ë‹¨ê³„ë³„ ê³„íš ìƒì„± ===
class Planner:
    def plan(self, user_prompt: str) -> list[str]:
        system = "You are a step-by-step planner. ë¶„ì„ ì£¼ì œë¥¼ ë‹¨ê³„ë³„ë¡œ ë‚˜ëˆ ì¤˜."
        resp = openai.ChatCompletion.create(
            model="gpt-4o",
            messages=[{"role":"system","content":system},
                      {"role":"user","content":user_prompt}],
            temperature=0
        )
        # ChatGPTê°€ JSON ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ë‹¨ê³„ ë°°ì—´ì„ ë°˜í™˜í•œë‹¤ê³  ê°€ì •
        return json.loads(resp.choices[0].message.content)

# === 1-B. Executor: ê° ë‹¨ê³„ ì‹¤í–‰ ë§¤í•‘ ===
class Executor:
    def execute(self, step: str, context: dict) -> any:
        if step == "ì›¹ ê²€ìƒ‰ ì‹¤í–‰":
            return perform_web_research_and_synthesis(context["user_prompt"])
        if step == "ì‹œì¥ ì°¨íŠ¸":
            return create_market_chart(context["last_result"])
        # í•„ìš”í•˜ë‹¤ë©´ ë” ë§ì€ ë§¤í•‘ì„ ì—¬ê¸°ì— ì¶”ê°€
        return None

# === 1-C. Memory: ê²°ê³¼ ì €ì¥/ì¬í™œìš© ===
class Memory:
    def __init__(self):
        self.store: list[dict] = []
    def remember(self, record: dict):
        self.store.append(record)
    def recall(self, topic: str) -> list[dict]:
        return [r for r in self.store if r.get("topic")==topic]

# === 1-D. Agent: Planner + Executor + Memory í†µí•© ===
class Agent:
    def __init__(self):
        self.planner = Planner()
        self.executor = Executor()
        self.memory = Memory()
    def run(self, user_prompt: str) -> str:
        # 1) ê³¼ê±° ê¸°ë¡ ì¡°íšŒ
        past = self.memory.recall(user_prompt)
        # 2) ë‹¨ê³„ë³„ ê³„íš ìˆ˜ë¦½
        steps = self.planner.plan(user_prompt)
        context = {"user_prompt": user_prompt, "past": past, "last_result": None}
        results = []
        # 3) ë‹¨ê³„ë³„ ì‹¤í–‰ ë° ê¸°ì–µ
        for step in steps:
            outcome = self.executor.execute(step, context)
            self.memory.remember({"topic": user_prompt, "step": step, "result": outcome})
            context["last_result"] = outcome
            results.append({"step": step, "result": outcome})
        # 4) ìµœì¢… ë‹µë³€ ìš”ì•½
        summary = openai.ChatCompletion.create(
            model="gpt-4o",
            messages=[
              {"role":"system","content":"Summarize the following step results into a final answer."},
              {"role":"user","content": json.dumps(results)}
            ],
            temperature=0
        ).choices[0].message.content
        return summary

def load_css(file_name):
    """ì§€ì •ëœ CSS íŒŒì¼ì„ ì½ì–´ Streamlit ì•±ì— ì ìš©í•˜ëŠ” í•¨ìˆ˜"""
    try:
        with open(file_name, "r", encoding="utf-8") as f:
            st.markdown(f"<style>{f.read()}</style>", unsafe_allow_html=True)
    except FileNotFoundError:
        st.warning(f"ê²½ê³ : '{file_name}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# --- 2. ë””ìì¸ ì‹œìŠ¤í…œ ë° ìƒìˆ˜ ì •ì˜ ---
CHART_COLOR_PALETTE = ['#6C5FF5', '#889AF5', '#B6BCFA', '#DDE0FD', '#78C4D3', '#A5D8E2']
CHART_BG_COLOR = "rgba(0,0,0,0)"
CHART_FONT_COLOR = "#EAEBF0"
GRID_COLOR = "rgba(255, 255, 255, 0.1)"

# --- 3. ì‚¬ì´ë“œë°” UI ì»´í¬ë„ŒíŠ¸ ---
def display_world_clocks():
    """ì„¸ê³„ ì£¼ìš” ë„ì‹œì˜ í˜„ì¬ ì‹œê°„ì„ í‘œì‹œí•˜ëŠ” ì‚¬ì´ë“œë°” ì»´í¬ë„ŒíŠ¸"""
    st.markdown("<h5><span class='icon-dot'></span> ì„¸ê³„ ì‹œê°„</h5>", unsafe_allow_html=True)
    now_default = datetime.now(pytz.timezone("Asia/Tokyo"))
    st.markdown(f"<p class='sidebar-date'>{now_default.strftime('%Yë…„ %mì›” %dì¼')}</p>", unsafe_allow_html=True)
    
    timezones = {
        "ë„ì¿„": "Asia/Tokyo", 
        "í•˜ë…¸ì´": "Asia/Ho_Chi_Minh", 
        "ë‘ë°”ì´": "Asia/Dubai", 
        "ì‹œì• í‹€": "America/Los_Angeles"
    }
    
    for city, tz in timezones.items():
        try:
            now = datetime.now(pytz.timezone(tz))
            st.markdown(f"""<div class="info-item"><span class="info-label">{city}</span><span class="info-value">{now.strftime('%H:%M')}</span></div>""", unsafe_allow_html=True)
        except Exception: 
            st.markdown(f"""<div class="info-item"><span class="info-label">{city}</span><span class="info-value error">ë¡œë“œ ì‹¤íŒ¨</span></div>""", unsafe_allow_html=True)

def display_exchange_rates():
    """ê³ ì • í™˜ìœ¨ ì •ë³´ë¥¼ í‘œì‹œí•˜ëŠ” ì‚¬ì´ë“œë°” ì»´í¬ë„ŒíŠ¸"""
    st.markdown("<h5><span class='icon-dot'></span> í™˜ìœ¨ ì •ë³´</h5>", unsafe_allow_html=True)

    # ê³ ì • í™˜ìœ¨
    usd_krw = 1350.0       # 1 USD -> 1,350 KRW
    jpy_100_krw = 930.0    # 100 JPY -> 930 KRW

    st.markdown(
        f"""<div class="info-item">
              <span class="info-label">USD (1ë‹¬ëŸ¬)</span>
              <span class="info-value">{usd_krw:,.0f} ì›</span>
           </div>""",
        unsafe_allow_html=True
    )
    st.markdown(
        f"""<div class="info-item">
              <span class="info-label">JPY (100ì—”)</span>
              <span class="info-value">{jpy_100_krw:,.0f} ì›</span>
           </div>""",
        unsafe_allow_html=True
    )



# --- 4. ë°ì´í„° íŒŒì‹± ë° ì‹œê°í™” ì»´í¬ë„ŒíŠ¸ ---

def parse_table_from_text(text: str) -> pd.DataFrame:
    """ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì˜ í…ìŠ¤íŠ¸ì—ì„œ í…Œì´ë¸”ì„ ì¶”ì¶œí•˜ì—¬ Pandas DataFrameìœ¼ë¡œ ë³€í™˜"""
    match = re.search(r'^\s*\|.*\|(?:\n|\r\n?)\|.*\|(?:\n|\r\n?)(?:\|.*\|\s*(?:\n|\r\n?))*', text, re.MULTILINE)
    if not match: return pd.DataFrame()
    
    table_str = match.group(0)
    lines = table_str.strip().split('\n')
    header = [h.strip() for h in lines[0].split('|') if h.strip()]
    data = []
    for line in lines[2:]:
        if '|' in line:
            values = [v.strip() for v in line.split('|') if v.strip()]
            if len(values) == len(header): data.append(values)
    return pd.DataFrame(data, columns=header)

def create_empty_chart(message: str) -> go.Figure:
    """ë°ì´í„° ë¶„ì„ ì‹¤íŒ¨ ì‹œ í‘œì‹œí•  ë¹ˆ ì°¨íŠ¸ë¥¼ ìƒì„±"""
    fig = go.Figure()
    fig.add_annotation(text=message, align='center', showarrow=False, font=dict(color="orange", size=14))
    fig.update_layout(xaxis=dict(showgrid=False, zeroline=False, visible=False), yaxis=dict(showgrid=False, zeroline=False, visible=False), paper_bgcolor=CHART_BG_COLOR, plot_bgcolor="rgba(255, 255, 255, 0.03)")
    return fig

def extract_numeric(series: pd.Series) -> pd.Series:
    """ë¬¸ìì—´ì´ í¬í•¨ëœ Seriesì—ì„œ ìˆ«ìë§Œ ì¶”ì¶œí•˜ì—¬ ìˆ«ìí˜• Seriesë¡œ ë³€í™˜"""
    return series.astype(str).str.extract(r'(\d+\.?\d*)').iloc[:, 0].astype(float)

def create_market_chart(text: str) -> go.Figure:
    df = parse_table_from_text(text)
    if df.empty or df.shape[1] < 2: return create_empty_chart("AIê°€ ìœ íš¨í•œ ì‹œì¥ ê·œëª¨ ë°ì´í„°ë¥¼<br>ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    try:
        label_col, value_col = df.columns[0], df.columns[1]
        def convert_korean_to_numeric(value_str):
            try:
                value_str = str(value_str).replace(',', '').strip()
                num_part_match = re.search(r'[\d\.]+', value_str)
                if not num_part_match: return 0
                num = float(num_part_match.group(0))
                multipliers = {'ì¡°': 1e12, 'ì–µ': 1e8, 'ë§Œ': 1e4}
                for unit, multiplier in multipliers.items():
                    if unit in value_str: num *= multiplier; break
                return num
            except (ValueError, IndexError): return 0
        df[value_col] = df[value_col].apply(convert_korean_to_numeric)
        if 'plan_data' not in st.session_state: st.session_state.plan_data = {}
        st.session_state.plan_data['market_analysis'] = df.to_dict('records')
        fig = go.Figure(data=[go.Pie(labels=df[label_col], values=df[value_col], hole=.6, marker_colors=CHART_COLOR_PALETTE, textinfo='label+percent', textfont_size=14, hoverinfo='label+value+percent')])
        fig.update_layout(showlegend=False, font_color=CHART_FONT_COLOR, paper_bgcolor=CHART_BG_COLOR, plot_bgcolor=CHART_BG_COLOR, margin=dict(t=10, b=10, l=10, r=10), annotations=[dict(text='ì‹œì¥', x=0.5, y=0.5, font_size=20, showarrow=False, font_color=CHART_FONT_COLOR)])
        return fig
    except Exception as e: return create_empty_chart(f"ì‹œì¥ ì°¨íŠ¸ ë Œë”ë§ ì˜¤ë¥˜: {e}")

def create_forrester_wave_chart(text: str) -> go.Figure:
    df = parse_table_from_text(text)
    if df.shape[1] < 4:
        return create_empty_chart("AIê°€ ìœ íš¨í•œ ê²½ìŸì‚¬ ë°ì´í„°ë¥¼<br>ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    try:
        df.columns = ['Competitor', 'Strategy', 'Current Offering', 'Market Presence']
        df = df[~df['Competitor'].str.contains('Competitor [A-Z]', case=False, na=False)]
        df = df[~df['Competitor'].str.contains('ê²½ìŸì‚¬ [A-Z]', case=False, na=False)]
        if df.empty or 'ë¶„ì„' in df['Competitor'].iloc[0]: return create_empty_chart("AIê°€ ì‹¤ì œ ê²½ìŸì‚¬ ì´ë¦„ ëŒ€ì‹ <br>Placeholderë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")

        df['Strategy'] = extract_numeric(df['Strategy'])
        df['Current Offering'] = extract_numeric(df['Current Offering'])
        df['Market Presence'] = extract_numeric(df['Market Presence'])

        df.dropna(subset=['Strategy', 'Current Offering'], inplace=True)
        df['Market Presence'].fillna(5, inplace=True)

        if df.empty:
            return create_empty_chart("AIê°€ ìƒì„±í•œ ë°ì´í„°ì— ìœ íš¨í•œ<br>ìˆ«ì ì ìˆ˜ê°€ ì—†ì–´ ì°¨íŠ¸ë¥¼ ê·¸ë¦´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
        x_mid, y_mid = 5.0, 5.0
        fig = px.scatter(df, x="Strategy", y="Current Offering", size="Market Presence", color="Competitor", hover_name="Competitor", hover_data={'Strategy': ':.1f', 'Current Offering': ':.1f', 'Market Presence': ':.1f'}, size_max=50, text="Competitor", color_discrete_sequence=px.colors.qualitative.Vivid)
        fig.update_traces(textposition='top center', marker=dict(line=dict(width=1, color='DarkSlateGrey'), opacity=0.7))
        fig.update_layout(xaxis_title="ì „ëµ (Strategy)", yaxis_title="í˜„ì¬ ì˜¤í¼ë§ (Current Offering)", font_color=CHART_FONT_COLOR, paper_bgcolor=CHART_BG_COLOR, plot_bgcolor=CHART_BG_COLOR, showlegend=False, xaxis=dict(range=[0, 10.5], showgrid=True, gridcolor=GRID_COLOR, zeroline=False), yaxis=dict(range=[0, 10.5], showgrid=True, gridcolor=GRID_COLOR, zeroline=False), margin=dict(t=20, b=20, l=20, r=20))
        fig.add_shape(type="rect", x0=x_mid, y0=y_mid, x1=10.5, y1=10.5, fillcolor="rgba(108, 95, 245, 0.1)", layer="below", line_width=0)
        fig.add_vline(x=x_mid, line_width=1, line_dash="dash", line_color="grey")
        fig.add_hline(y=y_mid, line_width=1, line_dash="dash", line_color="grey")
        fig.add_annotation(x=9.8, y=9.8, text="Leaders", showarrow=False, font=dict(color="#6C5FF5", size=14), xanchor='right', yanchor='top')
        fig.add_annotation(x=0.2, y=9.8, text="Strong Performers", showarrow=False, font=dict(color="grey"), xanchor='left', yanchor='top')
        fig.add_annotation(x=0.2, y=0.2, text="Contenders", showarrow=False, font=dict(color="grey"), xanchor='left', yanchor='bottom')
        fig.add_annotation(x=9.8, y=0.2, text="Challengers", showarrow=False, font=dict(color="grey"), xanchor='right', yanchor='bottom')
        return fig
    except Exception as e: 
        return create_empty_chart(f"Forrester Wave ì°¨íŠ¸ ë Œë”ë§ ì˜¤ë¥˜: {e}")

def display_persona_cards(text: str):
    df = parse_table_from_text(text)
    if df.empty or df.shape[1] < 5: 
        st.warning("í˜ë¥´ì†Œë‚˜ ë°ì´í„°ë¥¼ ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."); st.text(text); return
    try:
        df.columns = ['Persona', 'Age', 'Occupation', 'Goal', 'Pain_Point']
        if 'plan_data' not in st.session_state: st.session_state.plan_data = {}
        st.session_state.plan_data['personas'] = df.to_dict('records')
        cols = st.columns(min(len(df), 3))
        for i, row in df.iterrows():
            with cols[i % min(len(df), 3)]:
                st.markdown(f"""<div class="persona-card"><div class="persona-icon"></div><h4>{row['Persona']}</h4><p class="persona-info">{row['Occupation']} â€¢ {row['Age']}ì„¸</p><hr class="persona-divider"><h5>í•µì‹¬ ëª©í‘œ</h5><p>{row['Goal']}</p><h5>ê°€ì¥ í° ê³ ì¶©</h5><p>{row['Pain_Point']}</p></div>""", unsafe_allow_html=True)
    except Exception as e:
        st.error(f"í˜ë¥´ì†Œë‚˜ ì¹´ë“œ ìƒì„± ì˜¤ë¥˜: {e}"); st.markdown(text)

def create_priority_chart(text: str, topic: str) -> go.Figure:
    df = parse_table_from_text(text)
    required_cols = ['Reach', 'Impact', 'Confidence', 'Effort']
    header_map = {'ê¸°ëŠ¥': 'Feature', 'feature': 'Feature', 'ë„ë‹¬': 'Reach', 'reach': 'Reach', 'ì˜í–¥': 'Impact', 'impact': 'Impact', 'í™•ì‹ ': 'Confidence', 'confidence': 'Confidence', 'ë…¸ë ¥': 'Effort', 'effort': 'Effort'}
    
    if not df.empty:
        df.rename(columns=lambda c: header_map.get(c.strip().lower(), c.strip()), inplace=True)

    if df.empty or not all(col in df.columns for col in required_cols):
        with st.spinner("AI ì¶œë ¥ í˜•ì‹ ì˜¤ë¥˜ ê°ì§€. ìˆ˜ì •ì„ ìœ„í•´ ì¬ìš”ì²­í•©ë‹ˆë‹¤..."):
            correction_prompt = f"ì´ì „ ë‹µë³€ì˜ ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸”ì— RICE Score í•„ìˆ˜ ì»¬ëŸ¼ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤. ì£¼ì œ '{topic}'ì— ëŒ€í•´, ì»¬ëŸ¼ëª…ì´ ë°˜ë“œì‹œ **'ê¸°ëŠ¥', 'Reach', 'Impact', 'Confidence', 'Effort'**ì¸ ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸”ì„ ë‹¤ì‹œ ìƒì„±í•´ ì£¼ì‹­ì‹œì˜¤."
            corrected_text = stream_and_display_step(correction_prompt)
            df = parse_table_from_text(corrected_text)
            if df.empty: return create_empty_chart("AIì˜ ë‹µë³€ í˜•ì‹ì„ ìˆ˜ì •í•˜ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            df.rename(columns=lambda c: header_map.get(c.strip().lower(), c.strip()), inplace=True)
            if not all(col in df.columns for col in required_cols):
                return create_empty_chart("AIê°€ í•„ìˆ˜ ì»¬ëŸ¼ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    try:
        feature_col = 'Feature'
        if feature_col not in df.columns:
            potential_feature_col = df.columns[0]
            if potential_feature_col not in required_cols:
                df.rename(columns={potential_feature_col: 'Feature'}, inplace=True); feature_col = 'Feature'
            else: return create_empty_chart("ê¸°ëŠ¥(Feature)ì— í•´ë‹¹í•˜ëŠ” ì»¬ëŸ¼ì„<br>ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        df[required_cols] = df[required_cols].apply(pd.to_numeric, errors='coerce').fillna(0)
        df['Score'] = (df['Reach'] * df['Impact'] * df['Confidence']) / df['Effort'].replace(0, 1)
        if 'plan_data' not in st.session_state: st.session_state.plan_data = {}
        st.session_state.plan_data['key_features'] = df.sort_values(by='Score', ascending=False).to_dict('records')
        
        fig = px.scatter(df, x="Effort", y="Impact", size="Score", color=feature_col, hover_name=feature_col, size_max=60, color_discrete_sequence=CHART_COLOR_PALETTE)
        fig.update_layout(title_text='ê¸°ëŠ¥ ìš°ì„ ìˆœìœ„ (RICE Score)', title_x=0.5, xaxis_title="Effort (ë…¸ë ¥)", yaxis_title="Impact (ì˜í–¥ë ¥)", font_color=CHART_FONT_COLOR, paper_bgcolor=CHART_BG_COLOR, plot_bgcolor=CHART_BG_COLOR, legend_title_text='í•µì‹¬ ê¸°ëŠ¥', margin=dict(t=40, b=40, l=40, r=40))
        fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor=GRID_COLOR)
        fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor=GRID_COLOR)
        return fig
    except Exception as e: return create_empty_chart(f"ìš°ì„ ìˆœìœ„ ì°¨íŠ¸ ë Œë”ë§ ì˜¤ë¥˜: {e}")

def create_roadmap_gantt_chart(text: str) -> go.Figure:
    df = parse_table_from_text(text)
    if df.empty: return create_empty_chart("AIê°€ ìœ íš¨í•œ ë¡œë“œë§µ ë°ì´í„°ë¥¼<br>ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    try:
        task_col_name, start_col_name, finish_col_name = df.columns[0], df.columns[1], df.columns[2]
        df[start_col_name] = pd.to_datetime(df[start_col_name], errors='coerce')
        df[finish_col_name] = pd.to_datetime(df[finish_col_name], errors='coerce')
        df.dropna(subset=[start_col_name, finish_col_name], inplace=True)
        if df.empty: return create_empty_chart("ìœ íš¨í•œ ë‚ ì§œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        resource_col_name = df.columns[3] if len(df.columns) > 3 else None
        fig = px.timeline(df, x_start=start_col_name, x_end=finish_col_name, y=task_col_name, color=resource_col_name, color_discrete_sequence=CHART_COLOR_PALETTE)
        fig.update_yaxes(autorange="reversed")
        fig.update_layout(title_text='ì‹¤í–‰ ë¡œë“œë§µ', title_x=0.5, font_color=CHART_FONT_COLOR, paper_bgcolor=CHART_BG_COLOR, plot_bgcolor=CHART_BG_COLOR, legend_title_text='ë‹´ë‹¹', margin=dict(t=40, b=40, l=40, r=40))
        return fig
    except Exception as e: return create_empty_chart(f"ë¡œë“œë§µ ì°¨íŠ¸ ë Œë”ë§ ì˜¤ë¥˜: {e}")

def create_kpi_bar_chart(text: str) -> go.Figure:
    df = parse_table_from_text(text)
    if df.empty or len(df.columns) < 2: return create_empty_chart("AIê°€ ìœ íš¨í•œ KPI ë°ì´í„°ë¥¼<br>ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    try:
        kpi_col, target_col = df.columns[0], df.columns[1]
        df['numeric_target'] = pd.to_numeric(df[target_col].str.replace(r'[^0-9.]', '', regex=True), errors='coerce')
        fig = px.bar(df, x=kpi_col, y='numeric_target', text=target_col, color_discrete_sequence=CHART_COLOR_PALETTE)
        fig.update_traces(textposition='outside')
        fig.update_layout(title_text="í•µì‹¬ ëª©í‘œ(KPI)", title_x=0.5, font_color=CHART_FONT_COLOR, paper_bgcolor=CHART_BG_COLOR, plot_bgcolor=CHART_BG_COLOR, xaxis_title="", yaxis_title="", margin=dict(t=40, b=20, l=20, r=20))
        return fig
    except Exception as e: return create_empty_chart(f"KPI ì°¨íŠ¸ ë Œë”ë§ ì˜¤ë¥˜: {e}")

def create_pie_chart(text: str) -> go.Figure:
    df = parse_table_from_text(text)
    if df.empty or len(df.columns) < 2: return create_empty_chart("AIê°€ ìœ íš¨í•œ ë¹„ìœ¨ ë°ì´í„°ë¥¼<br>ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    try:
        label_col, value_col = df.columns[0], df.columns[1]
        df[value_col] = pd.to_numeric(df[value_col].str.replace(r'[^0-9.]', '', regex=True), errors='coerce')
        df.dropna(inplace=True)
        fig = px.pie(df, names=label_col, values=value_col, hole=0.4, color_discrete_sequence=CHART_COLOR_PALETTE)
        fig.update_traces(textposition='inside', textinfo='percent+label', pull=[0.05]*len(df))
        fig.update_layout(showlegend=False, font_color=CHART_FONT_COLOR, paper_bgcolor=CHART_BG_COLOR, plot_bgcolor=CHART_BG_COLOR, margin=dict(t=10, b=10, l=10, r=10))
        return fig
    except Exception as e: return create_empty_chart(f"íŒŒì´ ì°¨íŠ¸ ë Œë”ë§ ì˜¤ë¥˜: {e}")

def display_message_and_target_card(text: str):
    try:
        target_pattern = r"(?:íƒ€ê²Ÿ|íƒ€ê²Ÿ ê³ ê°|ì£¼ íƒ€ê²Ÿ)\s*[:]?\s*(.*?)(?=\n(?:-|\*|#)|ë©”ì‹œì§€|í•µì‹¬ ë©”ì‹œì§€|ìŠ¬ë¡œê±´|$)"
        message_pattern = r"(?:ë©”ì‹œì§€|í•µì‹¬ ë©”ì‹œì§€|ìŠ¬ë¡œê±´)\s*[:]?\s*\"?(.*?)\"?"
        target_match = re.search(target_pattern, text, re.IGNORECASE | re.DOTALL)
        message_match = re.search(message_pattern, text, re.IGNORECASE | re.DOTALL)
        target = target_match.group(1).strip() if target_match else "íƒ€ê²Ÿ ì •ë³´ ë¶„ì„ ì‹¤íŒ¨"
        message = (message_match.group(1).strip() if message_match else "") or stream_and_display_step(f"'{target}'ì— ëŒ€í•œ ì§§ê³  ê°•ë ¥í•œ í•µì‹¬ ë©”ì‹œì§€ë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œë§Œ ì œì•ˆí•´ì¤˜.")
        card_html = f"""<div class="message-card-container"><div class="message-card-target"><h6>TARGET AUDIENCE</h6><p>{target}</p></div><div class="message-card-slogan"><h6>CORE MESSAGE</h6><p>"{message}"</p></div></div>"""
        st.markdown(card_html, unsafe_allow_html=True)
    except Exception:
        st.warning("ë©”ì‹œì§€ ë° íƒ€ê²Ÿ ì •ë³´ ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. AI ì›ë³¸ ë‹µë³€ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        st.text(text)

def display_content_strategy_cards(text: str):
    df = parse_table_from_text(text)
    if df.empty:
        st.warning("ì½˜í…ì¸  ì „ëµ ë°ì´í„°ë¥¼ ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."); st.text(text); return
    try:
        df.columns = ['Format', 'Content']
        cols = st.columns(len(df) if len(df) <= 3 else 3)
        for i, row in df.iterrows():
            with cols[i % 3]:
                st.markdown(f"""<div class="content-strategy-card"><div class="content-card-header">{row['Format']}</div><div class="content-card-body">{row['Content']}</div></div>""", unsafe_allow_html=True)
    except Exception as e:
        st.error(f"ì½˜í…ì¸  ì „ëµ ì¹´ë“œ ìƒì„± ì˜¤ë¥˜: {e}"); st.dataframe(df)

def display_campaign_goals(text: str):
    """
    AIê°€ ë°˜í™˜í•œ â€˜ìº í˜ì¸ ëª©í‘œâ€™ ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸”ì„
    2ì»¬ëŸ¼ ì¹´ë“œ ìŠ¤íƒ€ì¼ë¡œ ì˜ˆì˜ê²Œ ë Œë”ë§í•©ë‹ˆë‹¤.
    """
    df = parse_table_from_text(text)
    if df.empty:
        # í…Œì´ë¸” íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì›ë³¸ í…ìŠ¤íŠ¸ ë…¸ì¶œ
        st.markdown(f"""
        <div style="background-color:#262730;border-radius:12px;padding:16px;margin-bottom:16px;">
            <pre style="color:#EAEBF0;white-space:pre-wrap;">{text}</pre>
        </div>""", unsafe_allow_html=True)
        return

    # ì»¬ëŸ¼ëª… ê³ ì •
    df.columns = ['Goal', 'KPI']
    cols = st.columns(2, gap="large")

    for idx, row in df.iterrows():
        with cols[idx % 2]:
            # ì²« ë²ˆì§¸ ì¹´ë“œë§Œ ë³´ë” ê°•ì¡°
            border = "border:2px solid #6C5FF5;" if idx == 0 else ""
            st.markdown(f"""
                <div style="background-color:#262730; border-radius:12px; {border} padding:20px; box-shadow:0 4px 12px rgba(0,0,0,0.3); margin-bottom:16px;">
                <h4 style="color:#EAEBF0; margin-bottom:8px;">{row['Goal']}</h4>
                <p style="color:#A5D8E2; font-size:0.9em; margin:0;">
                    í•µì‹¬ ì§€í‘œ(KPI): {row['KPI']}
                </p>
            </div>""", unsafe_allow_html=True)

def display_core_offer(text: str):
    """
    AIê°€ ë°˜í™˜í•œ â€˜í•µì‹¬ ì˜¤í¼â€™ ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸”ì„
    í˜ë¥´ì†Œë‚˜ ì¹´ë“œ ëŠë‚Œìœ¼ë¡œ 2ì»¬ëŸ¼ì— ë Œë”ë§í•©ë‹ˆë‹¤.
    """
    df = parse_table_from_text(text)
    if df.empty:
        # ì‹¤íŒ¨ ì‹œ ì›ë³¸ í…ìŠ¤íŠ¸ ë…¸ì¶œ
        st.markdown(f"""
        <div style="background-color:#262730;border-radius:12px;padding:16px;margin-bottom:16px;">
            <pre style="color:#EAEBF0;white-space:pre-wrap;">{text}</pre>
        </div>""", unsafe_allow_html=True)
        return

    # ì»¬ëŸ¼ëª… ê³ ì •
    df.columns = ['offer', 'condition', 'score']

    cols = st.columns(2, gap="large")
    for idx, row in df.iterrows():
        with cols[idx % 2]:
            # ì™¼ìª½ ì¹´ë“œ(ì²« ë²ˆì§¸)ëŠ” ê°•ì¡°ëœ ë³´ë”, ì˜¤ë¥¸ìª½ì€ ê¸°ë³¸
            border = "border:2px solid #6C5FF5;" if idx == 0 else ""
            st.markdown(f"""
            <div style="
                background-color: #262730;
                border-radius: 12px;
                {border}
                padding: 20px;
                box-shadow: 0 4px 12px rgba(0,0,0,0.3);
                margin-bottom: 16px;
            ">
                <h4 style="color:#EAEBF0; margin-bottom:8px;">{row['offer']}</h4>
                <p style="color:#A5D8E2; font-size:0.9em; margin:0 0 4px;">
                    ì¡°ê±´: {row['condition']}
                </p>
                <p style="color:#889AF5; font-size:0.9em; margin:0;">
                    ë§¤ë ¥ë„: {row['score']}/10
                </p>
            </div>""", unsafe_allow_html=True)

def create_sunburst_chart(text: str) -> go.Figure:
    df = parse_table_from_text(text)
    if df.empty or len(df.columns) < 3: return create_empty_chart("AIê°€ ìœ íš¨í•œ ì±„ë„ ë¯¹ìŠ¤ ë°ì´í„°ë¥¼<br>ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    try:
        df.columns = ['Category', 'Channel', 'Budget']
        df['Budget'] = pd.to_numeric(df['Budget'].str.replace('%','').str.strip(), errors='coerce')
        df.dropna(inplace=True)
        fig = px.sunburst(df, path=['Category', 'Channel'], values='Budget', color='Category', color_discrete_map={'(?)':'#262730', 'Owned':'#6C5FF5', 'Paid':'#889AF5', 'Earned':'#B6BCFA'})
        fig.update_traces(textinfo='label+percent entry', insidetextorientation='radial')
        fig.update_layout(title_text='ì±„ë„ ë¯¹ìŠ¤ ì „ëµ (Sunburst)', title_x=0.5, font_color=CHART_FONT_COLOR, paper_bgcolor=CHART_BG_COLOR, margin=dict(t=40, b=20, l=20, r=20))
        return fig
    except Exception as e: return create_empty_chart(f"ì¬ë²„ìŠ¤íŠ¸ ì°¨íŠ¸ ë Œë”ë§ ì˜¤ë¥˜: {e}")
        
def create_customer_segment_chart(text: str) -> go.Figure:
    df = parse_table_from_text(text)
    if df.empty or len(df.columns) < 3: return create_empty_chart("AIê°€ ìœ íš¨í•œ íƒ€ê²Ÿ ê³ ê° ë°ì´í„°ë¥¼<br>ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    try:
        df.columns = ['Group', 'Characteristic', 'Reach_Rate']
        df['Reach_Rate'] = pd.to_numeric(df['Reach_Rate'].str.replace('%','').str.strip(), errors='coerce')
        df.dropna(inplace=True)
        df = df.sort_values(by='Reach_Rate', ascending=True)
        fig = px.bar(df, x='Reach_Rate', y='Group', orientation='h', text='Characteristic', color='Reach_Rate', color_continuous_scale='Viridis')
        fig.update_traces(textposition='inside', insidetextanchor='end', textfont_size=12)
        fig.update_layout(xaxis_title="ì˜ˆìƒ ë„ë‹¬ë¥  (%)", yaxis_title="", font_color=CHART_FONT_COLOR, paper_bgcolor=CHART_BG_COLOR, plot_bgcolor=CHART_BG_COLOR, margin=dict(t=20, b=40, l=20, r=20))
        return fig
    except Exception as e: return create_empty_chart(f"íƒ€ê²Ÿ ê³ ê° ì°¨íŠ¸ ë Œë”ë§ ì˜¤ë¥˜: {e}")
        
def create_text_display_fig(text: str) -> go.Figure:
    fig = go.Figure()
    fig.add_annotation(text=text.replace("\n", "<br>"), align='left', showarrow=False, x=0.05, y=0.95, xref="paper", yref="paper", font=dict(color="white", size=14), xanchor='left', yanchor='top')
    fig.update_layout(xaxis=dict(showgrid=False, zeroline=False, visible=False), yaxis=dict(showgrid=False, zeroline=False, visible=False), paper_bgcolor=CHART_BG_COLOR, plot_bgcolor=CHART_BG_COLOR, height=300, margin=dict(t=20, b=20, l=20, r=20))
    return fig

def stream_and_display_step(prompt: str) -> str:
    full_response = ""
    system_prompt = "You are a world-class business consultant. Respond in Korean. When asked for a table, generate it in a simple, clean Markdown format. You must not add any conversational text or explanations before or after the table. Only the markdown table is allowed."
    try:
        stream = openai.chat.completions.create(model="gpt-4o", messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": prompt}], stream=True)
        for chunk in stream:
            full_response += (chunk.choices[0].delta.content or "")
        return full_response
    except Exception as e:
        st.error(f"AI ì‘ë‹µ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"); return ""

def get_deep_dive_analysis(topic: str, step_title: str, ai_response: str) -> str:
    deep_dive_prompt = f"""...""" # ì „ì²´ í”„ë¡¬í”„íŠ¸ ë‚´ìš©
    try:
        response = openai.chat.completions.create(model="gpt-4o", messages=[{"role": "user", "content": deep_dive_prompt}], temperature=0.7)
        return response.choices[0].message.content
    except Exception as e:
        return f"ì‹¬ì¸µ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"

def perform_web_research_and_synthesis(topic: str) -> str:
    st.markdown("<h3>ì‹¤ì‹œê°„ ì›¹ ë¦¬ì„œì¹˜</h3>", unsafe_allow_html=True)

    # â”€â”€â”€ ì„œìš¸ íƒ€ì„ì¡´ ê¸°ì¤€ í˜„ì¬ ì—°ë„ë¥¼ ê³„ì‚° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    current_year = datetime.now(pytz.timezone("Asia/Seoul")).year

    with st.spinner("ë¦¬ì„œì¹˜ ì „ëµ ìˆ˜ë¦½ ë° ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„± ì¤‘..."):
        query_gen_prompt = (
            f'ì£¼ì œ "{topic}"ì— ëŒ€í•œ ì‹¬ì¸µ ë¶„ì„ì„ ìœ„í•´, ì‹œì¥ í¬ê¸°, ê²½ìŸì‚¬, ìµœì‹  ê¸°ìˆ , '
            f'íƒ€ê²Ÿ ê³ ê° ê´€ì ì˜ íš¨ê³¼ì ì¸ ì›¹ ê²€ìƒ‰ ì¿¼ë¦¬ 4ê°œë¥¼ JSON ë¦¬ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ ìƒì„±í•´ì¤˜. '
            f'ê° ì¿¼ë¦¬ì— ë°˜ë“œì‹œ "{current_year}ë…„"ì„ í¬í•¨í•´ì¤˜. ë‹¤ë¥¸ ì„¤ëª…ì€ ì œì™¸í•´ì¤˜.'
        )
        try:
            response = openai.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": query_gen_prompt}],
                response_format={"type": "json_object"},
                temperature=0
            )
            search_queries = json.loads(response.choices[0].message.content).get("queries", [])
        except Exception as e:
            st.error(f"ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„± ì‹¤íŒ¨: {e}")
            return ""

    if not search_queries:
        st.warning("ë¶„ì„ì— í•„ìš”í•œ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return ""

    with st.container(border=True):
        st.markdown("##### ìƒì„±ëœ ê²€ìƒ‰ ì¿¼ë¦¬")
        st.json(search_queries)

    # â”€â”€â”€ ì›¹ ê²€ìƒ‰ ì‹¤í–‰ ë° ê²°ê³¼ ìˆ˜ì§‘ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    search_results_text = ""
    with st.spinner("4ê°œì˜ ì›¹ ê²€ìƒ‰ì„ ë™ì‹œì— ì‹¤í–‰í•©ë‹ˆë‹¤... (ì„±ëŠ¥ ìµœì í™”)"):
        def search_task(query):
            try:
                return tavily.search(query=query, search_depth="advanced")
            except Exception:
                return None

        with ThreadPoolExecutor(max_workers=4) as executor:
            for result in executor.map(search_task, search_queries):
                if result:
                    for hit in result.get('results', []):
                        search_results_text += (
                            f"ì œëª©: {hit['title']}\n"
                            f"URL: {hit['url']}\n"
                            f"ë‚´ìš©: {hit['content']}\n\n"
                        )

    if not search_results_text:
        st.error("ì›¹ ë¦¬ì„œì¹˜ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆê±°ë‚˜, ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return ""

    # â”€â”€â”€ AI ì¢…í•© ë¸Œë¦¬í•‘ ìƒì„± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    synthesis_prompt = (
        f'"{topic}"ì— ëŒ€í•œ ë‹¤ìŒ ì›¹ ë¦¬ì„œì¹˜ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ, '
        f'ë‹¤ìŒ ê° í•­ëª©ì— ëŒ€í•´ ë¶„ì„í•˜ê³ , ë°˜ë“œì‹œ "- *í•­ëª©ëª…*" í˜•ì‹ìœ¼ë¡œ ì‹œì‘í•˜ì—¬ '
        f'êµ¬ì¡°í™”ëœ "{current_year}ë…„ ê¸°ì¤€ ì´ˆê¸° ë¦¬ì„œì¹˜ ë¸Œë¦¬í•‘"ì„ ì‘ì„±í•´ì¤˜: '
        f'í•µì‹¬ ìš”ì•½, ì‹œì¥ ë™í–¥, ì£¼ìš” ê²½ìŸì‚¬, ì£¼ìš” íƒ€ê²Ÿ ê³ ê°, í•µì‹¬ ê¸°ìˆ , ì£¼ìš” í†µê³„'
    )

    try:
        st.success("ì›¹ ë¦¬ì„œì¹˜ ì™„ë£Œ! AIê°€ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ë¸Œë¦¬í•‘ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤...")
        response_placeholder = st.empty()

        def stream_generator():
            stream = openai.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": synthesis_prompt}],
                stream=True
            )
            for chunk in stream:
                yield chunk.choices[0].delta.content or ""

        full_context = "".join(response_placeholder.write_stream(stream_generator()))
        return full_context

    except Exception as e:
        st.error(f"ë¦¬ì„œì¹˜ ì¢…í•© ì‹¤íŒ¨: {e}")
        return ""


def display_research_briefing(context: str):
    st.markdown("<h3>AI ë¦¬ì„œì¹˜ ë¸Œë¦¬í•‘ (ì¬êµ¬ì„±)</h3>", unsafe_allow_html=True)
    sections = {"í•µì‹¬ ìš”ì•½": "summary", "ì‹œì¥ ë™í–¥": "trends", "í•µì‹¬ í”Œë ˆì´ì–´": "competitors", "ì£¼ìš” ê²½ìŸì‚¬": "competitors", "ì£¼ìš” íƒ€ê²Ÿ ê³ ê°": "audience", "í•µì‹¬ ê¸°ìˆ ": "tech", "ì£¼ìš” í†µê³„": "stats"}
    parsed_sections = {}
    for key in sections.keys():
        pattern = re.compile(rf"-\s*\*+{re.escape(key)}\*+.*?\n(.*?)(?=\n\s*-\s*\*|\Z)", re.DOTALL | re.IGNORECASE)
        match = pattern.search(context)
        if match and key not in parsed_sections:
            parsed_sections[key] = match.group(1).strip()
    if not parsed_sections:
        st.warning("AI ë¸Œë¦¬í•‘ì„ ì„¹ì…˜ë³„ë¡œ ë¶„ì„í•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì›ë³¸ í…ìŠ¤íŠ¸ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤."); st.text(context); return

    briefing_html = '<div class="briefing-container">'
    for key, content in parsed_sections.items():
        icon_class = sections.get(key, "summary")
        briefing_html += f"""<div class="briefing-section"><div class="briefing-header"><div class="briefing-icon {icon_class}"></div><h4>{key}</h4></div><div class="briefing-content">{content.replace(chr(10), "<br>")}</div></div>"""
    briefing_html += '</div>'
    st.markdown(briefing_html, unsafe_allow_html=True)

def execute_pipeline(pipeline_name: str, steps: dict, topic: str, research_context: str, competitor_names: list = []):
    st.markdown(f"<div class='pipeline-header'>{pipeline_name} ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤.</div>", unsafe_allow_html=True)
    step_titles = list(steps.keys())
    progress_placeholder = st.empty()
    if 'deep_dive_status' not in st.session_state: st.session_state.deep_dive_status = {}

    def update_progress_bar(current_step_index):
        progress_items = []
        for i, title in enumerate(step_titles):
            if i < current_step_index: progress_items.append(f"<span class='progress-item done'>{title}</span>")
            elif i == current_step_index: progress_items.append(f"<span class='progress-item working'>{title}</span>")
            else: progress_items.append(f"<span class='progress-item pending'>{title}</span>")
        progress_html = f"<div class='progress-bar'>{''.join(progress_items)}</div>"
        progress_placeholder.markdown(progress_html, unsafe_allow_html=True)

    step_items = list(steps.items())
    master_step_index = 0
    while master_step_index < len(step_items):
        title, details = step_items[master_step_index]
        group_name = details.get("layout_group")
        if group_name:
            group_steps_data = []
            temp_index = master_step_index
            while temp_index < len(step_items) and step_items[temp_index][1].get("layout_group") == group_name:
                group_steps_data.append(step_items[temp_index]); temp_index += 1
            update_progress_bar(master_step_index)
            st.markdown(f'<h3>{master_step_index + 1}. {group_name}</h3>', unsafe_allow_html=True)
            with st.container():
                st.markdown('<div class="step-content-card">', unsafe_allow_html=True)
                cols = st.columns(len(group_steps_data))
                full_group_text_result = ""
                for i, (step_title, step_details) in enumerate(group_steps_data):
                    with cols[i]:
                        if step_title == "ê²½ìŸì‚¬ êµ¬ë„" and not competitor_names:
                            st.markdown(f"<h5>{step_title}</h5>", unsafe_allow_html=True)
                            fig = create_empty_chart("ì›¹ ë¦¬ì„œì¹˜ì—ì„œ ìœ íš¨í•œ<br>ê²½ìŸì‚¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì—ˆìŠµë‹ˆë‹¤.")
                            st.plotly_chart(fig, use_container_width=True)
                            continue
                        with st.spinner(f"{step_title} ë¶„ì„ ì¤‘..."):
                            previous_steps_summary = ""
                            if st.session_state.get('plan_data'):
                                if 'personas' in st.session_state.plan_data: previous_steps_summary += f"- íƒ€ê²Ÿ í˜ë¥´ì†Œë‚˜: {', '.join([p['Persona'] for p in st.session_state.plan_data['personas']])}\n"
                                if 'key_features' in st.session_state.plan_data and st.session_state.plan_data['key_features']: previous_steps_summary += f"- í•µì‹¬ ê¸°ëŠ¥: {st.session_state.plan_data['key_features'][0].get('Feature', 'N/A')}\n"
                            
                            augmented_prompt = f'"{step_details["prompt_template"].format(p=topic)}"'
                            text_result = stream_and_display_step(augmented_prompt)
                            full_group_text_result += f"--- {step_title} ---\n{text_result}\n\n"
                        if text_result:
                            st.markdown(f"<h5>{step_title}</h5>", unsafe_allow_html=True)
                            display_type = step_details.get("display_type", "chart")
                            if display_type == "chart":
                                if step_details["func"] == create_priority_chart: fig = step_details["func"](text_result, topic)
                                else: fig = step_details["func"](text_result)
                                st.plotly_chart(fig, use_container_width=True, key=f"{pipeline_name}_{master_step_index}_{i}")
                            elif display_type == "custom":
                                step_details["func"](text_result)
                        else: st.error(f"{step_title} ë°ì´í„° ë¶„ì„ ì‹¤íŒ¨")
                st.markdown('</div>', unsafe_allow_html=True)
            with st.expander("AI ì›ë³¸ ë‹µë³€ ë³´ê¸° (ê·¸ë£¹)"): st.text(full_group_text_result or "AI ë‹µë³€ ì—†ìŒ")
            deep_dive_key = f"deep_dive_{pipeline_name}_{master_step_index}"
            if st.button(f"'{group_name}' ë¶„ì„ ê·¼ê±° ë”ë³´ê¸°", key=f"show_{deep_dive_key}", use_container_width=True):
                with st.spinner("ì‹¬ì¸µ ë¶„ì„ ì¤‘..."):
                    deep_dive_content = get_deep_dive_analysis(topic, group_name, full_group_text_result)
                    st.info(deep_dive_content)
            if master_step_index < len(steps) - len(group_steps_data): st.markdown("<hr class='step-divider'>", unsafe_allow_html=True)
            master_step_index += len(group_steps_data)
        else:
            update_progress_bar(master_step_index)
            st.markdown(f'<h3>{master_step_index+1}. {title}</h3>', unsafe_allow_html=True)
            with st.container():
                st.markdown('<div class="step-content-card">', unsafe_allow_html=True)
                with st.spinner(f"{title} ë¶„ì„ ì¤‘..."):
                    previous_steps_summary = ""
                    if st.session_state.get('plan_data'):
                        if 'personas' in st.session_state.plan_data: previous_steps_summary += f"- íƒ€ê²Ÿ í˜ë¥´ì†Œë‚˜: {', '.join([p['Persona'] for p in st.session_state.plan_data['personas']])}\n"
                        if 'key_features' in st.session_state.plan_data and st.session_state.plan_data['key_features']:
                            previous_steps_summary += f"- í•µì‹¬ ê¸°ëŠ¥: {st.session_state.plan_data['key_features'][0].get('Feature', 'N/A')}\n"
                    augmented_prompt = f'"{details["prompt_template"].format(p=topic)}"'
                    text_result = stream_and_display_step(augmented_prompt)
                if text_result:
                    display_type = details.get("display_type", "chart")
                    if display_type == "chart":
                        if details["func"] == create_priority_chart:
                            fig = details["func"](text_result, topic)
                        else:
                            fig = details["func"](text_result)
                        st.plotly_chart(fig, use_container_width=True, key=f"{pipeline_name}_{master_step_index}")
                    elif display_type == "custom":
                        details["func"](text_result)
                else: st.error("ë°ì´í„° ë¶„ì„ ì‹¤íŒ¨")
                st.markdown('</div>', unsafe_allow_html=True)
            with st.expander("AI ì›ë³¸ ë‹µë³€ ë³´ê¸°"): st.text(text_result or "AI ë‹µë³€ ì—†ìŒ")
            deep_dive_key = f"deep_dive_{pipeline_name}_{master_step_index}"
            if st.button(f"'{title}' ë¶„ì„ ê·¼ê±° ë”ë³´ê¸°", key=f"show_{deep_dive_key}", use_container_width=True):
                 with st.spinner("ì‹¬ì¸µ ë¶„ì„ ì¤‘..."):
                    deep_dive_content = get_deep_dive_analysis(topic, title, text_result)
                    st.info(deep_dive_content)
            if master_step_index < len(steps) - 1: st.markdown("<hr class='step-divider'>", unsafe_allow_html=True)
            master_step_index += 1
    update_progress_bar(len(steps))

def get_competitor_data(topic: str, research_context: str) -> list[str]:
    """ë¦¬ì„œì¹˜ ë‚´ìš©ì—ì„œ ê²½ìŸì‚¬ ëª©ë¡ë§Œ ì •í™•íˆ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜"""
    with st.spinner("AI ë¦¬ì„œì¹˜ ë¸Œë¦¬í•‘ì—ì„œ ê²½ìŸì‚¬ ëª©ë¡ ì¶”ì¶œ ì¤‘..."):
        prompt = f"ë‹¤ìŒì€ '{topic}'ì— ëŒ€í•œ ë¦¬ì„œì¹˜ ë‚´ìš©ì…ë‹ˆë‹¤. ì´ ë‚´ìš©ì—ì„œ ì–¸ê¸‰ëœ **ì£¼ìš” ê²½ìŸì‚¬ ë˜ëŠ” í•µì‹¬ í”Œë ˆì´ì–´ì˜ ì´ë¦„**ë§Œ ì¶”ì¶œí•˜ì—¬ JSON í˜•ì‹ì˜ ë¦¬ìŠ¤íŠ¸ë¡œ ì‘ë‹µí•´ì£¼ì‹­ì‹œì˜¤. ë‹¤ë¥¸ ì„¤ëª…ì€ ì ˆëŒ€ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”. ì˜ˆ: {{\"competitors\": [\"Google\", \"Cloudflare\", \"Akamai\"]}}\n\n---\n{research_context}"
        try:
            response = openai.chat.completions.create(model="gpt-4o", messages=[{"role": "user", "content": prompt}], response_format={"type": "json_object"}, temperature=0)
            competitors = json.loads(response.choices[0].message.content).get("competitors", [])
            return competitors
        except Exception:
            return []

def product_planning_pipeline(topic: str, research_context: str, competitor_names: list):
    st.markdown("<h2>I. ì œí’ˆ ê¸°íš ë¶„ì„</h2>", unsafe_allow_html=True)
    competitor_list_str = ", ".join(competitor_names) if competitor_names else "ë¦¬ì„œì¹˜ì—ì„œ ë°œê²¬ëœ ê²½ìŸì‚¬ ì—†ìŒ"
    forrester_prompt = f"ë‹¤ìŒ ê²½ìŸì‚¬ ë¦¬ìŠ¤íŠ¸({competitor_list_str})ë¥¼ ê¸°ë°˜ìœ¼ë¡œ Forrester Wave ë¶„ì„ì„ ìˆ˜í–‰í•´ì¤˜. **ë¦¬ìŠ¤íŠ¸ì— ì—†ëŠ” ê²½ìŸì‚¬ë¥¼ ì ˆëŒ€ ì„ì˜ë¡œ ì¶”ê°€í•˜ì§€ ë§ˆì‹œì˜¤.** ê° ê²½ìŸì‚¬ë³„ Strategyì™€ Current Offeringì€ **0.0ì—ì„œ 10.0 ì‚¬ì´ ìˆ«ì ê°’**ìœ¼ë¡œë§Œ í‘œí˜„í•´ì•¼ í•´. ë§Œì•½ ë¦¬ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆë‹¤ë©´, 'Competitor' ì»¬ëŸ¼ì— 'ë¶„ì„í•  ê²½ìŸì‚¬ ì—†ìŒ'ì´ë¼ê³  ë‹µë³€í•˜ëŠ” í…Œì´ë¸”ì„ ìƒì„±í•´ì¤˜. ì»¬ëŸ¼ëª…ì€ 'Competitor', 'Strategy', 'Current Offering', 'Market Presence'ë¡œ ì •í™•íˆ ìƒì„±í•´ì•¼ í•´."
    steps = {
        "ì‹œì¥ ìŠ¤ëƒ…ìƒ·": {"prompt_template": "ì£¼ì œ '{p}'ì˜ ì‹œì¥ ê·œëª¨(TAM, SAM, SOM)ë¥¼ ì¶”ì •í•˜ê³  ì„±ì¥ ê°€ëŠ¥ì„±ì„ ë¶„ì„í•˜ëŠ” ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸”(ì»¬ëŸ¼: êµ¬ë¶„, ê·œëª¨(ì›), ê·¼ê±°)ì„ ë§Œë“¤ì–´ì¤˜.", "display_type": "chart", "func": create_market_chart, "layout_group": "ì´ˆê¸° ì‹œì¥ ë¶„ì„"},
        "ê²½ìŸì‚¬ êµ¬ë„": {"prompt_template": forrester_prompt, "display_type": "chart", "func": create_forrester_wave_chart, "layout_group": "ì´ˆê¸° ì‹œì¥ ë¶„ì„"},
        "íƒ€ê²Ÿ í˜ë¥´ì†Œë‚˜": {"prompt_template": "ì£¼ì œ '{p}'ì˜ í•µì‹¬ íƒ€ê²Ÿ í˜ë¥´ì†Œë‚˜ 3ëª…ì„ ì •ì˜í•˜ê³ , ê° í˜ë¥´ì†Œë‚˜ì˜ ì´ë¦„, ë‚˜ì´, ì§ì—…, í•µì‹¬ ëª©í‘œ(Goal), ê°€ì¥ í° ê³ ì¶©(Pain Point)ì„ ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸”ë¡œ ë§Œë“¤ì–´ì¤˜.", "display_type": "custom", "func": display_persona_cards},
        "ê¸°ëŠ¥ ìš°ì„ ìˆœìœ„": {"prompt_template": "ì£¼ì œ '{p}'ì— í•„ìš”í•œ í•µì‹¬ ê¸°ëŠ¥ 5ê°€ì§€ë¥¼ ì •ì˜í•˜ê³ , RICE ì ìˆ˜ë¥¼ 10ì  ë§Œì ìœ¼ë¡œ í‰ê°€í•˜ëŠ” ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸”ì„ ë§Œë“¤ì–´ì¤˜. ì»¬ëŸ¼ëª…ì€ ë°˜ë“œì‹œ **'ê¸°ëŠ¥', 'Reach', 'Impact', 'Confidence', 'Effort'**ë¡œ ìƒì„±í•´ì¤˜.", "display_type": "chart", "func": create_priority_chart},
        "ì œí’ˆ ì¶œì‹œ ë¡œë“œë§µ": {"prompt_template": f"'{topic}'ì˜ 1ë…„ ë¡œë“œë§µì„ 5ë‹¨ê³„ë¡œ ë‚˜ëˆ„ì–´ ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸”(Task, Start, Finish, Resource)ë¡œ ë§Œë“¤ì–´ì¤˜. ë‚ ì§œëŠ” {datetime.now().year+1}-MM-DD í˜•ì‹ìœ¼ë¡œ.", "display_type": "chart", "func": create_roadmap_gantt_chart}
    }
    execute_pipeline("ì œí’ˆ ê¸°íš", steps, topic, research_context, competitor_names)

def promotion_planning_pipeline(topic: str, research_context: str):
    st.markdown("<h2>II. í”„ë¡œëª¨ì…˜ ê¸°íš ë¶„ì„</h2>", unsafe_allow_html=True)
    steps = {
        "í”„ë¡œëª¨ì…˜ ëª©í‘œ(KPI)": {"prompt_template": "ì•ì„  ë¶„ì„ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ, '{p}' í”„ë¡œëª¨ì…˜ì„ ìœ„í•œ êµ¬ì²´ì ì¸ í•µì‹¬ ëª©í‘œ 3ê°€ì§€ë¥¼ 'KPI', 'ëª©í‘œì¹˜' ì»¬ëŸ¼ì˜ ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸”ë¡œ ë§Œë“¤ì–´ì¤˜.", "display_type": "chart", "func": create_kpi_bar_chart, "layout_group": "í”„ë¡œëª¨ì…˜ ëª©í‘œ ë° íƒ€ê²Ÿ"},
        "íƒ€ê²Ÿ ê³ ê°": {"prompt_template": "ì•ì„œ ì •ì˜ëœ íƒ€ê²Ÿ í˜ë¥´ì†Œë‚˜ ê¸°ë°˜ìœ¼ë¡œ '{p}' í”„ë¡œëª¨ì…˜ì˜ íƒ€ê²Ÿ ê³ ê° ê·¸ë£¹ 3ê°œë¥¼ 'ê³ ê° ê·¸ë£¹', 'íŠ¹ì§•', 'ì˜ˆìƒ ë„ë‹¬ë¥ (%)' ì»¬ëŸ¼ì˜ ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸”ë¡œ ë§Œë“¤ì–´ì¤˜.", "display_type": "chart", "func": create_customer_segment_chart, "layout_group": "í”„ë¡œëª¨ì…˜ ëª©í‘œ ë° íƒ€ê²Ÿ"},
        "í•µì‹¬ ì˜¤í¼": {"prompt_template": "ê²½ìŸì‚¬ì™€ íŠ¸ë Œë“œ, ìš°ë¦¬ ì œí’ˆ ê¸°ëŠ¥ì„ ê³ ë ¤í•˜ì—¬ '{p}' í”„ë¡œëª¨ì…˜ì˜ ë§¤ë ¥ì ì¸ í˜œíƒ 3ê°€ì§€ë¥¼ 'ì˜¤í¼ ë‚´ìš©', 'ì¡°ê±´', 'ë§¤ë ¥ë„(10ì )' ì»¬ëŸ¼ì˜ ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸”ë¡œ ë§Œë“¤ì–´ì¤˜.", "display_type": "custom", "func": display_core_offer},
        "í™ë³´ ì±„ë„": {"prompt_template": "íƒ€ê²Ÿ ê³ ê°ì´ ì£¼ë¡œ í™œë™í•˜ëŠ” ì±„ë„ ì¤‘ì‹¬ìœ¼ë¡œ '{p}' í”„ë¡œëª¨ì…˜ í™ë³´ ì±„ë„ 4ê°œì™€ ì˜ˆìƒ ì˜ˆì‚° ë¹„ìœ¨(%)ì„ 'ì±„ë„', 'ì˜ˆì‚° ë¹„ìœ¨(%)' ì»¬ëŸ¼ì˜ ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸”ë¡œ ë§Œë“¤ì–´ì¤˜.", "display_type": "chart", "func": create_pie_chart},
        "ê¸°ê°„ ë° ì¼ì •": {"prompt_template": f"'{topic}' í”„ë¡œëª¨ì…˜ì˜ ì£¼ìš” ì¼ì •ì„ 4ë‹¨ê³„ë¡œ ë‚˜ëˆ„ì–´ ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸”(Task, Start, Finish)ë¡œ ë§Œë“¤ì–´ì¤˜. ë‚ ì§œëŠ” {datetime.now().year+1}-MM-DD í˜•ì‹ìœ¼ë¡œ.", "display_type": "chart", "func": create_roadmap_gantt_chart}
    }
    execute_pipeline("í”„ë¡œëª¨ì…˜ ê¸°íš", steps, topic, research_context)

def marketing_campaign_pipeline(topic: str, research_context: str):
    st.markdown("<h2>III. ë§ˆì¼€íŒ… ìº í˜ì¸ ë¶„ì„</h2>", unsafe_allow_html=True)
    steps = {
        "ìº í˜ì¸ ëª©í‘œ": {"prompt_template": "'{p}' ë§ˆì¼€íŒ… ìº í˜ì¸ì˜ êµ¬ì²´ì ì¸ ëª©í‘œ 3ê°€ì§€ë¥¼ 'ëª©í‘œ', 'í•µì‹¬ì§€í‘œ(KPI)' ì»¬ëŸ¼ì˜ ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸”ë¡œ ë§Œë“¤ì–´ì¤˜. ë‹µë³€ì€ í…Œì´ë¸” ì™¸ì— ë‹¤ë¥¸ ì„¤ëª…ì„ í¬í•¨í•˜ì§€ ë§ˆ.", "display_type": "custom", "func": display_campaign_goals},
        "íƒ€ê²Ÿ & í•µì‹¬ ë©”ì‹œì§€": {"prompt_template": "ì£¼ì œ '{p}' ìº í˜ì¸ì— ê°€ì¥ ì¤‘ìš”í•œ íƒ€ê²Ÿ ê³ ê° í•œ ê·¸ë£¹ì„ ì •ì˜í•˜ê³ , ê·¸ë“¤ì˜ ë§ˆìŒì„ ì‚¬ë¡œì¡ì„ ì§§ê³  ê°•ë ¥í•œ í•µì‹¬ ìŠ¬ë¡œê±´ì„ ì œì•ˆí•´ì¤˜. ë‹µë³€ì€ ë°˜ë“œì‹œ 'íƒ€ê²Ÿ: [ê°„ê²°í•œ íƒ€ê²Ÿ ì„¤ëª…]'ê³¼ 'í•µì‹¬ ë©”ì‹œì§€: \"[ê¸°ì–µí•˜ê¸° ì‰¬ìš´ ìŠ¬ë¡œê±´]\"' ë‘ ì¤„ë¡œë§Œ ì‘ì„±í•´ì¤˜.", "display_type": "custom", "func": display_message_and_target_card},
        "ì½˜í…ì¸  ì „ëµ": {"prompt_template": "ìµœì‹  íŠ¸ë Œë“œë¥¼ ë°˜ì˜í•˜ì—¬ '{p}' ìº í˜ì¸ì„ ìœ„í•œ í•µì‹¬ ì½˜í…ì¸  ì•„ì´ë””ì–´ 3ê°€ì§€ë¥¼ 'ì½˜í…ì¸  í˜•ì‹', 'ì£¼ìš” ë‚´ìš©' ì»¬ëŸ¼ì˜ ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸”ë¡œ ë§Œë“¤ì–´ì¤˜.", "display_type": "custom", "func": display_content_strategy_cards},
        "ì±„ë„ ë¯¹ìŠ¤": {"prompt_template": "'{p}' ìº í˜ì¸ì— í™œìš©í•  ë¯¸ë””ì–´ ì±„ë„ ë¯¹ìŠ¤ë¥¼ 'ì±„ë„ êµ¬ë¶„(Owned/Paid/Earned)', 'ì±„ë„ëª…', 'ì˜ˆì‚° ë¹„ì¤‘(%)' ì»¬ëŸ¼ì˜ ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸”ë¡œ ë§Œë“¤ì–´ì¤˜.", "display_type": "chart", "func": create_sunburst_chart},
        "ì‹¤í–‰ íƒ€ì„ë¼ì¸": {"prompt_template": f"'{topic}' ìº í˜ì¸ì˜ 3ê°œì›” íƒ€ì„ë¼ì¸ì„ ì£¼ìš” ë§ˆì¼ìŠ¤í†¤ë³„ë¡œ ë‚˜ëˆ„ì–´ ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸”(Task, Start, Finish)ë¡œ ë§Œë“¤ì–´ì¤˜. ë‚ ì§œëŠ” {datetime.now().year+1}-MM-DD í˜•ì‹ìœ¼ë¡œ.", "display_type": "chart", "func": create_roadmap_gantt_chart}
    }
    execute_pipeline("ë§ˆì¼€íŒ… ìº í˜ì¸ ê¸°íš", steps, topic, research_context)

def classify_intent(user_prompt: str) -> str:
    system_prompt = "ì‚¬ìš©ì ìš”ì²­ì„ 'PLANNING_REQUEST' ë˜ëŠ” 'GENERAL_QUESTION'ìœ¼ë¡œ ë¶„ë¥˜í•´. ì œí’ˆ, ì„œë¹„ìŠ¤, í”„ë¡œëª¨ì…˜, ë§ˆì¼€íŒ…, ì‚¬ì—… ê¸°íš ë° ë¶„ì„ì€ PLANNING_REQUESTì•¼. ê·¸ ì™¸ëŠ” GENERAL_QUESTIONì´ì•¼."
    try:
        response = openai.chat.completions.create(model="gpt-4o-mini", messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": user_prompt}], temperature=0)
        intent = response.choices[0].message.content.strip()
        st.toast(f"ìš”ì²­ ì˜ë„ ë¶„ì„: {intent}")
        return intent
    except Exception as e: st.error(f"ì˜ë„ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}"); return "GENERAL_QUESTION"

def run_intelligent_agent(user_prompt):
    if 'plan_data' not in st.session_state:
        st.session_state.plan_data = {}
    
    intent = classify_intent(user_prompt)

    if intent == "PLANNING_REQUEST":
        agent = Agent()
        final_answer = agent.run(user_prompt)
        st.markdown(final_answer)
        with st.expander("ğŸ§  ì—ì´ì „íŠ¸ ì‚¬ê³ /í–‰ë™/ê´€ì°° ë¡œê·¸", expanded=False):
            for idx, log in enumerate(st.session_state["cot_log"], start=1):
                st.markdown(
                    f"**{idx}. Thought:** {log['thought']}\n"
                    f"> **Action:** {log['action']}\n"
                    f"> **Observation:** {log['observation']}"
                )
    else:
        with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
            response = openai.chat.completions.create(model="gpt-4o", messages=[{"role": "user", "content": user_prompt}])
            st.markdown(response.choices[0].message.content)

def main():
    st.set_page_config(page_title="PENTHENA AI Agent", layout="wide", initial_sidebar_state="expanded")
    load_css("style.css")

    # --------------------------------------------------------------------
    # íˆ¬ëª… ë°°ê²½ì„ ëª» ë®ê³  ìˆëŠ” ìœ„ì ¯ë“¤ì„ í•œ ë²ˆì— íˆ¬ëª… ì²˜ë¦¬í•˜ëŠ” CSS
    # --------------------------------------------------------------------
    st.markdown("""
    <style>
      /* 1) ëª¨ë“  Markdown ì»¨í…Œì´ë„ˆ (st.markdown, st.empty.write_stream) */
      div[data-testid="stMarkdownContainer"],
      div[class*="css-"] > div[class*="css-"] {
        background-color: transparent !important;
        border: none !important;
      }
    
      /* 2) st.text() ì¶œë ¥ë¶€ */
      div[data-testid="stText"] {
        background-color: transparent !important;
      }
      div[data-testid="stText"] pre {
        background-color: transparent !important;
        border: none !important;
      }
    
      /* 3) Expander ë‚´ë¶€ ì˜ì—­ (ì—´ë ¤ìˆê±°ë‚˜ ë‹«í˜€ìˆê±°ë‚˜ ëª¨ë‘) */
      section[data-testid="stExpander"] > div[role="region"] {
        background-color: transparent !important;
        border: none !important;
      }
    
      /* 4) write_stream() / st.empty() ê°€ ê·¸ë¦¬ëŠ” ì˜ì—­ 
         (css-* í´ë˜ìŠ¤ê°€ ëœë¤ì´ë¼ [class*="css-"]ë¡œ í¬ê´„) */
      div[class*="css-"] > div[class*="css-"] {
        background-color: transparent !important;
      }
    </style>
    """, unsafe_allow_html=True)

    st.markdown("""
    <style>
      /* 1) JSON ìœ„ì ¯ ë°°ê²½ íˆ¬ëª…í™” */
      div[data-testid="stJson"] {
        background-color: transparent !important;
        border: none !important;
      }
    
      /* 2) ìŠ¤í”¼ë„ˆ / ì„±ê³µ ë©”ì‹œì§€ ë°•ìŠ¤(ìŠ¤íŠ¸ë¦¼ë¦¿ ìƒíƒœ ìœ„ì ¯) ë°°ê²½ íˆ¬ëª…í™” */
      div[data-testid="stStatusWidget"] {
        background-color: transparent !important;
      }
    
      /* 3) ëª¨ë“  <pre> íƒœê·¸ (ì½”ë“œ ë¸”ë¡) ë°°ê²½ íˆ¬ëª…í™” */
      pre {
        background-color: transparent !important;
        border: none !important;
      }
    
      /* 4) í™•ì¥(expander) ë³¸ë¬¸ ì¤‘ ë˜ í° ë¸”ë¡ì´ ë‚¨ì•„ ìˆìœ¼ë©´ ëŒ€ë¹„ìš© */
      section[data-testid="stExpander"] div[role="button"] + div > div {
        background-color: transparent !important;
      }
    </style>
    """, unsafe_allow_html=True)

    # ---  ì¶”ê°€: ê¸°ë³¸ í°ìƒ‰ ë°°ê²½ íˆ¬ëª… ì²˜ë¦¬  ---
    st.markdown("""
    <style>
      /* ì±„íŒ… ì…ë ¥ì°½ ë°°ê²½ ì—†ì• ê¸° */
      div[data-testid="stChatInput"] > div {
        background-color: transparent !important;
      }
      div[data-testid="stChatInput"] textarea {
        background-color: transparent !important;
        color: #EAEBF0 !important;
      }
    
      /* expander(â€œAI ì›ë³¸ ë‹µë³€ ë³´ê¸°â€) ë‚´ìš© ë°°ê²½ ì—†ì• ê¸° */
      section[data-testid="stExpander"] > div[role="button"] + div {
        background-color: transparent !important;
      }
    
      /* expander ì•ˆì˜ í…ìŠ¤íŠ¸ ì˜ì—­ */
      section[data-testid="stExpander"] .stMarkdown > div {
        background-color: transparent !important;
      }
    
      /* ë²„íŠ¼Â·ì…ë ¥ ìœ„ì ¯ ì£¼ë³€ ì¹´ë“œ ì˜ì—­ë„ íˆ¬ëª… ì²˜ë¦¬ (í•„ìš”ì‹œ) */
      .css-1d391kg .css-1outpf7 {
        background-color: transparent !important;
      }
    </style>
    """, unsafe_allow_html=True)

    # â”€â”€ ì»¤ìŠ¤í…€ ì‚¬ì´ë“œë°” ìŠ¤íƒ€ì¼ â”€â”€
    st.markdown("""
    <style>
      /* 1) ì‚¬ì´ë“œë°” í­ ê³ ì • (ì›í•˜ëŠ” ë„ˆë¹„ë¡œ ì¡°ì •) */
      [data-testid="stSidebar"] {
        width: 320px !important;
        min-width: 320px !important;
        max-width: 320px !important;
      }
      /* 2) ì‚¬ì´ë“œë°” ë“œë˜ê·¸ í•¸ë“¤ ë¹„í™œì„±í™” */
      [data-testid="columnResizer"] {
        pointer-events: none;
      }

      /* 3) info-item ê°„ê²© ì¢íˆê¸° */
      .info-item {
        display: flex;
        align-items: center;
        justify-content: space-between;
        margin-bottom: 4px;      /* ì•„ë˜ ì•„ì´í…œê³¼ ì„¸ë¡œ ê°„ê²© */
      }
      .info-item .info-label {
        white-space: nowrap;      /* ë ˆì´ë¸” ì¤„ë°”ê¿ˆ ê¸ˆì§€ */
        margin-right: 6px;        /* ë ˆì´ë¸”â†’ê°’ ê°„ ê°€ë¡œ ê°„ê²© */
      }
      .info-item .info-value {
        min-width: 40px;          /* ê°’ ë°•ìŠ¤ ìµœì†Œ ë„ˆë¹„ */
        padding: 2px 4px;         /* ì•ˆìª½ ì—¬ë°± */
        background-color: #262730;
        color: #EAEBF0;
        border-radius: 4px;
        text-align: center;
        font-weight: 500;
        white-space: nowrap;      /* ìˆ«ì ì¤„ë°”ê¿ˆ ê¸ˆì§€ */
      }

      /* 4) ì‚­ì œ ë²„íŠ¼ í…ìŠ¤íŠ¸ ì¤„ë°”ê¿ˆ ë°©ì§€ & ìµœì†Œ ë„ˆë¹„ */
      [data-testid="stSidebar"] .stButton > button {
        white-space: nowrap !important;
        min-width: 50px;          /* ë²„íŠ¼ ìµœì†Œ ë„ˆë¹„ */
        padding: 4px 8px;         /* ë²„íŠ¼ ì•ˆìª½ ì—¬ë°± */
      }
    </style>
    """, unsafe_allow_html=True)

    with st.sidebar:
        st.markdown('<div class="sidebar-logo">PENTHENA</div>', unsafe_allow_html=True)
        if st.button("ìƒˆ ë¶„ì„ ì‹œì‘", use_container_width=True, type="primary", key="new_analysis_sidebar"):
            st.session_state.clear()
            st.rerun()

        st.divider()
        display_world_clocks()
        st.divider()
        display_exchange_rates()
        st.markdown("#### ğŸ—„ï¸ Memory")
        if st.session_state["long_term"]:
            st.json(st.session_state["long_term"], expanded=False)
        else:
            st.caption("ì €ì¥ëœ ë©”ëª¨ë¦¬ ì—†ìŒ")
        st.divider()

        # â”€â”€ ë¶„ì„ ê¸°ë¡ + ì‚­ì œ ë²„íŠ¼ â”€â”€
        col1, col2 = st.columns([0.8, 0.2])
        with col1:
            st.markdown("<h5><span class='icon-dot'></span> ë¶„ì„ ê¸°ë¡</h5>", unsafe_allow_html=True)
        with col2:
            # ì •í™•íˆ 8ì¹¸ ë“¤ì—¬ì“°ê¸°(4 + 4)ì…ë‹ˆë‹¤
            if st.button("ì‚­ì œ", use_container_width=True, key="clear_history", type="primary"):
                st.session_state.prompt_history = []
                st.rerun()
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

        if 'prompt_history' not in st.session_state:
            st.session_state.prompt_history = []
        for i, prompt_text in enumerate(st.session_state.prompt_history[:5]):
            if st.button(prompt_text, key=f"history_{i}", use_container_width=True, type="secondary"):
                st.session_state.clear()
                st.session_state.messages = [{"role": "user", "content": prompt_text}]
                st.rerun()

    st.markdown('<div class="main-content">', unsafe_allow_html=True)
    st.title("PENTHENA Intelligence")
    st.write("ë¶„ì„í•˜ê³  ì‹¶ì€ ê¸°íš ì£¼ì œë¥¼ ììœ ë¡­ê²Œ ì…ë ¥í•´ì£¼ì„¸ìš”. AIê°€ ì‹¤ì‹œê°„ ì›¹ ë¦¬ì„œì¹˜ë¥¼ í†µí•´ í†µí•© ë¹„ì¦ˆë‹ˆìŠ¤ í”Œëœì„ ìƒì„±í•©ë‹ˆë‹¤.")

    if 'messages' not in st.session_state: st.session_state.messages = []
    
   

    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"], unsafe_allow_html=True)

    if prompt := st.chat_input("ìƒˆë¡œìš´ ê¸°íš ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤..."):
        st.session_state.clear()
        st.session_state.messages = [{"role": "user", "content": prompt}]
        if 'prompt_history' not in st.session_state: st.session_state.prompt_history = []
        st.session_state.prompt_history.insert(0, prompt)
        st.rerun()

    if st.session_state.get('messages') and 'last_prompt' not in st.session_state:
        user_prompt = st.session_state.messages[-1]["content"]
        st.session_state.last_prompt = user_prompt
        with st.chat_message("assistant"):
            run_intelligent_agent(user_prompt)

    st.markdown('</div>', unsafe_allow_html=True)

if __name__ == "__main__":
    main()
